{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/kirushi/.conda/envs/guardrails1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/u/kirushi/.conda/envs/guardrails1/lib/python3.9/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2024-02-15 00:07:57.133518: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-15 00:08:01.695460: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-15 00:08:09.762216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Downloading shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 537.39it/s]\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:24<00:00, 12.40s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# BitsAndBytesConfig to quantize the model int-4 config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "llm_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "model = AutoModelForCausalLM.from_pretrained(llm_name, device_map='auto', quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[INST] Give me list atleast five popular leaders name [/INST] 1. Elon Musk\\n2. Angela Merkel\\n3. Barack Obama\\n4. Xi Jinping\\n5. Oprah Winfrey',\n",
       " ' 1. Elon Musk\\n2. Angela Merkel\\n3. Barack Obama\\n4. Xi Jinping\\n5. Oprah Winfrey')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the loaded model\n",
    "prompt = \"[INST] Give me list atleast five popular leaders name [/INST]\"\n",
    "\n",
    "encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
    "model_inputs = encoded_input.to('cuda')\n",
    "\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "decoded_output = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "response = decoded_output[0][len(prompt):]\n",
    "\n",
    "decoded_output[0],response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 96.0/96.0 [00:00<00:00, 412kB/s]\n",
      "Downloading data files:   0%|                                                                                                   | 0/3 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|                                                                                                    | 0.00/282k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 282k/282k [00:00<00:00, 792kB/s]\u001b[A\n",
      "Downloading data files:  33%|██████████████████████████████▎                                                            | 1/3 [00:00<00:00,  2.71it/s]\n",
      "Downloading data:   0%|                                                                                                   | 0.00/50.0k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 50.0k/50.0k [00:00<00:00, 389kB/s]\u001b[A\n",
      "Downloading data files:  67%|████████████████████████████████████████████████████████████▋                              | 2/3 [00:00<00:00,  4.25it/s]\n",
      "Downloading data:   0%|                                                                                                   | 0.00/58.8k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 58.8k/58.8k [00:00<00:00, 451kB/s]\u001b[A\n",
      "Downloading data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.57it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1652.82it/s]\n",
      "Generating train split: 7225 examples [00:00, 55377.21 examples/s]\n",
      "Generating validation split: 1275 examples [00:00, 187580.68 examples/s]\n",
      "Generating test split: 1500 examples [00:00, 190864.18 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['CGPA', 'Internships', 'Projects', 'Workshops/Certifications', 'AptitudeTestScore', 'SoftSkillsRating', 'ExtracurricularActivities', 'PlacementTraining', 'SSC_Marks', 'HSC_Marks', 'PlacementStatus'],\n",
       "        num_rows: 7225\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['CGPA', 'Internships', 'Projects', 'Workshops/Certifications', 'AptitudeTestScore', 'SoftSkillsRating', 'ExtracurricularActivities', 'PlacementTraining', 'SSC_Marks', 'HSC_Marks', 'PlacementStatus'],\n",
       "        num_rows: 1275\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['CGPA', 'Internships', 'Projects', 'Workshops/Certifications', 'AptitudeTestScore', 'SoftSkillsRating', 'ExtracurricularActivities', 'PlacementTraining', 'SSC_Marks', 'HSC_Marks', 'PlacementStatus'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset with train, test, and validation splits\n",
    "dataset = load_dataset('Krooz/Campus_Recruitment_CSV')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CGPA': 7.7,\n",
       " 'Internships': 1,\n",
       " 'Projects': 1,\n",
       " 'Workshops/Certifications': 0,\n",
       " 'AptitudeTestScore': 69,\n",
       " 'SoftSkillsRating': 4.0,\n",
       " 'ExtracurricularActivities': 'No',\n",
       " 'PlacementTraining': 'No',\n",
       " 'SSC_Marks': 55,\n",
       " 'HSC_Marks': 69,\n",
       " 'PlacementStatus': 'NotPlaced'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def data_to_text_prompt(x):\n",
    "    \n",
    "    x = dict(x)\n",
    "    label = x['PlacementStatus']\n",
    "    x.pop('PlacementStatus')\n",
    "    json_data = json.dumps(x, indent=4)\n",
    "    \n",
    "    prompt = f\"\"\"[INST] Instruction:\n",
    "Write an objective overview about the following colleage student based only on the provided structured data in the JSON format.\n",
    "You should include details and cover the information mentioned in the placement data. The overview should be 100 - 200 words. \n",
    "Don’t make up information. Don't give any additional feedback just represent the given information in the overview. \n",
    "Use a random human name for the student, Dont start with 'based on the structured data'\n",
    "\n",
    "Structured data:\n",
    "{json_data}\n",
    "\n",
    "- SSC_Marks denote marks attained by the student in senion secondary school\n",
    "- HSC_Marks denote marks attained by the student in higher seconday school\n",
    "- CGPA is the cummulative GPA attained by the student in his university\n",
    " \n",
    "Overview:\n",
    "[/INST]\"\"\"\n",
    "    \n",
    "    return {'prompt': prompt, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Meet Maria. Maria is a current university student with a 7.7 CGPA, indicating strong academic performance in her college years. She has completed one internship and one project, demonstrating a practical application of her academic knowledge and a willingness to learn through real-world experiences. Maria does not have any work\n"
     ]
    }
   ],
   "source": [
    "prompt = data_to_text_prompt(dataset['train'][0])['prompt']\n",
    "\n",
    "encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
    "model_inputs = encoded_input.to('cuda')\n",
    "\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=500, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "decoded_output = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "print(decoded_output[0][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'label'],\n",
       "        num_rows: 7225\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'label'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['prompt', 'label'],\n",
       "        num_rows: 1275\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_datasets = dataset.map(\n",
    "    data_to_text_prompt, batched=False, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "new_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '[INST] Instruction:\\nWrite an objective overview about the following colleage student based only on the provided structured data in the JSON format.\\nYou should include details and cover the information mentioned in the placement data. The overview should be 100 - 200 words. \\nDon’t make up information. Don\\'t give any additional feedback just represent the given information in the overview. \\nUse a random human name for the student, Dont start with \\'based on the structured data\\'\\n\\nStructured data:\\n{\\n    \"CGPA\": 7.7,\\n    \"Internships\": 1,\\n    \"Projects\": 1,\\n    \"Workshops/Certifications\": 0,\\n    \"AptitudeTestScore\": 69,\\n    \"SoftSkillsRating\": 4.0,\\n    \"ExtracurricularActivities\": \"No\",\\n    \"PlacementTraining\": \"No\",\\n    \"SSC_Marks\": 55,\\n    \"HSC_Marks\": 69\\n}\\n\\n- SSC_Marks denote marks attained by the student in senion secondary school\\n- HSC_Marks denote marks attained by the student in higher seconday school\\n- CGPA is the cummulative GPA attained by the student in his university\\n \\nOverview:\\n[/INST]',\n",
       " 'label': 'NotPlaced'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview_response(x):\n",
    "    encoded_input = tokenizer(x['prompt'],  return_tensors=\"pt\", add_special_tokens=True)\n",
    "    model_inputs = encoded_input.to('cuda')\n",
    "    \n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=500, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    decoded_output = tokenizer.batch_decode(generated_ids[:, model_inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "    \n",
    "    return {'response': decoded_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_datasets = new_datasets.map(\n",
    "    overview_response, batched=True, batch_size = 256\n",
    ")\n",
    "new_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_datasets['train'].to_csv('text_dataset/train.csv')\n",
    "new_datasets['test'].to_csv('text_dataset/test.csv')\n",
    "new_datasets['validation'].to_csv('text_dataset/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
